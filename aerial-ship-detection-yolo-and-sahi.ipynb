{"cells":[{"cell_type":"markdown","metadata":{"id":"Zvsk7icHMTni"},"source":["\n","\n","\n","1.  Airraft carrier\n","2.  Auxiliary Ships\n","3.  Barge\n","4.  Cargo\n","5.  Commander\n","6.  Container Ship\n","7.  Cruiser\n","8.  Destroyer\n","9.  Dock\n","10. Ferry\n","11. Fishing Vessel\n","12. Frigate\n","13. Hovercraft\n","14. Landing Ship\n","15. Motorboat\n","16. Oil tanker\n","17. Merchant Ship\n","18. Other Ship\n","19. Other Warship\n","20. Patrol\n","21. RORO\n","22. Sailboat\n","23. Submarine\n","24. Tugboat\n","25. Yacht"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:02:28.572590Z","iopub.status.busy":"2024-06-13T09:02:28.572230Z","iopub.status.idle":"2024-06-13T09:02:29.604628Z","shell.execute_reply":"2024-06-13T09:02:29.603867Z","shell.execute_reply.started":"2024-06-13T09:02:28.572560Z"},"id":"2BDMpzqTMPV0","trusted":true},"outputs":[],"source":["# Import basic Libaries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import sklearn\n","%matplotlib inline\n","plt.style.use('default')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.execute_input":"2024-06-13T09:02:30.705131Z","iopub.status.busy":"2024-06-13T09:02:30.704611Z","iopub.status.idle":"2024-06-13T09:02:37.313179Z","shell.execute_reply":"2024-06-13T09:02:37.312158Z","shell.execute_reply.started":"2024-06-13T09:02:30.705080Z"},"id":"pT5fWn2bMYIr","outputId":"09d072ed-9391-4036-acdb-0fa62e392dc4","trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from torch import nn # nn imports all pytorch building blocks for neural networking\n","torch.__version__\n","\n","# Make device agnostic code\n","import torch._dynamo.config\n","torch._dynamo.config.suppress_errors = True # pytorch 2.0 to use torch.compile\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:02:37.315174Z","iopub.status.busy":"2024-06-13T09:02:37.314704Z","iopub.status.idle":"2024-06-13T09:02:37.638309Z","shell.execute_reply":"2024-06-13T09:02:37.637573Z","shell.execute_reply.started":"2024-06-13T09:02:37.315146Z"},"id":"9YEBBeuAMZhN","trusted":true},"outputs":[],"source":["# Import Torch Vision\n","import torchvision\n","from torchvision import datasets\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from torchvision.transforms import ToTensor  # transforms images to tensors"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-13T09:02:37.639572Z","iopub.status.busy":"2024-06-13T09:02:37.639304Z","iopub.status.idle":"2024-06-13T09:02:37.653455Z","shell.execute_reply":"2024-06-13T09:02:37.652780Z","shell.execute_reply.started":"2024-06-13T09:02:37.639549Z"},"id":"NFBNPjyCMa7N","outputId":"a50427b3-d3d8-4208-e827-9bdcaee1f4a0","trusted":true},"outputs":[],"source":["# to take model information\n","try:\n","    import torchinfo\n","except:\n","    !pip install torchinfo\n","    import torchinfo\n","\n","from torchinfo import summary"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-13T09:02:37.656074Z","iopub.status.busy":"2024-06-13T09:02:37.655666Z","iopub.status.idle":"2024-06-13T09:02:53.069852Z","shell.execute_reply":"2024-06-13T09:02:53.068693Z","shell.execute_reply.started":"2024-06-13T09:02:37.656043Z"},"id":"WKIEmXcSMdsq","outputId":"d43a38d2-a841-4744-d39f-c3ba210c22ba","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.31-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m723.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\n","Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\n","Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\n","Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\n","Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\n","Collecting ultralytics-thop>=0.2.5 (from ultralytics)\n","  Downloading ultralytics_thop-0.2.8-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.2.31-py3-none-any.whl (780 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.6/780.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-0.2.8-py3-none-any.whl (25 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.2.31 ultralytics-thop-0.2.8\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"Nl8unNxqMln2"},"source":["# Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:02:53.071510Z","iopub.status.busy":"2024-06-13T09:02:53.071216Z","iopub.status.idle":"2024-06-13T09:02:53.080924Z","shell.execute_reply":"2024-06-13T09:02:53.080190Z","shell.execute_reply.started":"2024-06-13T09:02:53.071482Z"},"id":"xRpgGgyhOWTu","trusted":true},"outputs":[],"source":["train_images = \"/kaggle/input/ships-data-yolo-version-25classes/train/images\"\n","train_labels = \"/kaggle/input/ships-data-yolo-version-25classes/train/labels\"\n","\n","val_images = \"/kaggle/input/ships-data-yolo-version-25classes/valid/images\"\n","val_labels = \"/kaggle/input/ships-data-yolo-version-25classes/valid/labels\"\n","\n","data_yaml = \"/kaggle/input/ships-data-yolo-version-25classes/data.yaml\""]},{"cell_type":"markdown","metadata":{"id":"UZYj3j--QSED"},"source":["# Model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-13T09:02:53.082246Z","iopub.status.busy":"2024-06-13T09:02:53.081951Z","iopub.status.idle":"2024-06-13T09:02:53.376040Z","shell.execute_reply":"2024-06-13T09:02:53.375150Z","shell.execute_reply.started":"2024-06-13T09:02:53.082213Z"},"id":"U31X46qdQzIm","outputId":"fcc35453-4db4-493d-9e08-e2706eabab65","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The image has dimensions 640x640 and 3 channels.\n"]}],"source":["# Load an image using OpenCV\n","import cv2\n","image = cv2.imread(\"/kaggle/input/ships-data-yolo-version-25classes/train/images/000006_bmp_jpg.rf.fe44953b88a4d81b3fdd6309597fad07.jpg\")\n","\n","# Get the size of the image\n","height, width, channels = image.shape\n","print(f\"The image has dimensions {width}x{height} and {channels} channels.\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:02:53.377534Z","iopub.status.busy":"2024-06-13T09:02:53.377241Z","iopub.status.idle":"2024-06-13T09:02:53.506536Z","shell.execute_reply":"2024-06-13T09:02:53.505465Z","shell.execute_reply.started":"2024-06-13T09:02:53.377507Z"},"id":"Z78ayOqCvPC6","trusted":true},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"markdown","metadata":{},"source":["# YOLOv9-x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:02:53.507936Z","iopub.status.busy":"2024-06-13T09:02:53.507618Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9e.pt to 'yolov9e.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 112M/112M [00:00<00:00, 250MB/s]  \n"]},{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.31 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9e.pt, data=/kaggle/input/ships-data-yolo-version-25classes/data.yaml, epochs=100, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 755k/755k [00:00<00:00, 14.4MB/s]\n","2024-06-13 09:02:57,577\tINFO util.py:124 -- Outdated packages:\n","  ipywidgets==7.7.1 found, needs ipywidgets>=8\n","Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","2024-06-13 09:02:58,439\tINFO util.py:124 -- Outdated packages:\n","  ipywidgets==7.7.1 found, needs ipywidgets>=8\n","Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=25\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1         0  ultralytics.nn.modules.block.Silence         []                            \n","  1                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  2                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  3                  -1  1    252160  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 2]        \n","  4                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n","  5                  -1  1   1004032  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 2]       \n","  6                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  7                  -1  1   4006912  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 1024, 512, 256, 2]      \n","  8                  -1  1   2623488  ultralytics.nn.modules.block.ADown           [1024, 1024]                  \n","  9                  -1  1   4269056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 1024, 512, 256, 2]     \n"," 10                   1  1      4160  ultralytics.nn.modules.block.CBLinear        [64, [64]]                    \n"," 11                   3  1     49344  ultralytics.nn.modules.block.CBLinear        [256, [64, 128]]              \n"," 12                   5  1    229824  ultralytics.nn.modules.block.CBLinear        [512, [64, 128, 256]]         \n"," 13                   7  1    984000  ultralytics.nn.modules.block.CBLinear        [1024, [64, 128, 256, 512]]   \n"," 14                   9  1   2033600  ultralytics.nn.modules.block.CBLinear        [1024, [64, 128, 256, 512, 1024]]\n"," 15                   0  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[0, 0, 0, 0, 0]]             \n"," 17                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[1, 1, 1, 1]]                \n"," 19                  -1  1    252160  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 2]        \n"," 20                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n"," 21    [12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[2, 2, 2]]                   \n"," 22                  -1  1   1004032  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 2]       \n"," 23                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n"," 24        [13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[3, 3]]                      \n"," 25                  -1  1   4006912  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 1024, 512, 256, 2]      \n"," 26                  -1  1   2623488  ultralytics.nn.modules.block.ADown           [1024, 1024]                  \n"," 27            [14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[4]]                         \n"," 28                  -1  1   4269056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 1024, 512, 256, 2]     \n"," 29                  -1  1    787968  ultralytics.nn.modules.block.SPPELAN         [1024, 512, 256]              \n"," 30                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 31            [-1, 25]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 32                  -1  1   4005888  ultralytics.nn.modules.block.RepNCSPELAN4    [1536, 512, 512, 256, 2]      \n"," 33                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 34            [-1, 22]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 35                  -1  1   1069056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 2]      \n"," 36                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n"," 37            [-1, 32]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 38                  -1  1   3612672  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 2]       \n"," 39                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n"," 40            [-1, 29]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 41                  -1  1  12860416  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 1024, 512, 2]     \n"," 42        [35, 38, 41]  1   5602075  ultralytics.nn.modules.head.Detect           [25, [256, 512, 512]]         \n","YOLOv9e summary: 1225 layers, 58164187 parameters, 58164171 gradients, 192.8 GFLOPs\n","\n","Transferred 1805/1811 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240613_090340-r49sioma</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tejasdashpute/YOLOv8/runs/r49sioma' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/tejasdashpute/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tejasdashpute/YOLOv8' target=\"_blank\">https://wandb.ai/tejasdashpute/YOLOv8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tejasdashpute/YOLOv8/runs/r49sioma' target=\"_blank\">https://wandb.ai/tejasdashpute/YOLOv8/runs/r49sioma</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Freezing layer 'model.42.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.23M/6.23M [00:00<00:00, 71.0MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ships-data-yolo-version-25classes/train/labels... 2209 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2209/2209 [00:08<00:00, 256.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/train/images/003313_bmp_jpg.rf.d20a8e352ccf1762ddbe11b05e6f329f.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/train/images/004153_bmp_jpg.rf.10f2ada766e80f906426e4dabb127ddb.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/train/images/2487__0_1498_bmp_jpg.rf.20b79625c01640e63a45c6e6b4a11a3c.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/train/images/2562__2760_2345_bmp_jpg.rf.b1acc85b79c4e43c2e23a5250cea08b8.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/train/images/2562__3207_2345_bmp_jpg.rf.e2520ff5600701c11e410d3667e98ece.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/train/images/2564__1840_2345_bmp_jpg.rf.41977998c1ff6553085935406caa017f.jpg: 2 duplicate labels removed\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/ships-data-yolo-version-25classes/train is not writeable, cache not saved.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/ships-data-yolo-version-25classes/valid/labels... 553 images, 0 backgrounds, 0 corrupt: 100%|██████████| 553/553 [00:02<00:00, 252.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/valid/images/1418__0_0_bmp_jpg.rf.d3388579efa061739f5f27cc588d441c.jpg: 2 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/valid/images/1907__2012_1840_bmp_jpg.rf.5ce541da79da79a419318b032daac34a.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/ships-data-yolo-version-25classes/valid/images/2562__3207_1840_bmp_jpg.rf.27bc9d2d39389f490c71884e8d321c89.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/ships-data-yolo-version-25classes/valid is not writeable, cache not saved.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000345, momentum=0.9) with parameter groups 298 weight(decay=0.0), 310 weight(decay=0.0005), 309 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      1/100      12.4G      1.131      2.879      1.258         14        640: 100%|██████████| 277/277 [03:58<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:23<00:00,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        553       3035      0.258      0.251      0.123     0.0799\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      2/100        12G      1.102      2.263      1.244         15        640: 100%|██████████| 277/277 [03:48<00:00,  1.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:22<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        553       3035      0.183      0.321      0.197      0.134\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      3/100      11.6G      1.108      2.153      1.271         16        640: 100%|██████████| 277/277 [03:45<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:22<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        553       3035      0.238      0.374      0.243      0.166\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      4/100      11.6G      1.116      2.093       1.26          3        640: 100%|██████████| 277/277 [03:45<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:22<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        553       3035      0.482      0.304      0.257      0.178\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      5/100      11.4G      1.082      1.977      1.238         28        640: 100%|██████████| 277/277 [03:45<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:21<00:00,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        553       3035      0.428      0.363      0.326       0.23\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      7/100      12.2G      1.021      1.782      1.205          6        640: 100%|██████████| 277/277 [03:45<00:00,  1.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 35/35 [00:21<00:00,  1.60it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        553       3035      0.405       0.43      0.362      0.263\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      8/100      11.4G     0.9932      1.731      1.188         56        640:  87%|████████▋ | 240/277 [03:15<00:29,  1.24it/s]"]}],"source":[" # Loading a pretrained model\n","model = YOLO('yolov9e.pt')\n","\n","# Training the model\n","model.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n","            epochs = 100,\n","            imgsz = height,\n","            seed = 42,\n","            batch = 8)"]},{"cell_type":"markdown","metadata":{},"source":["# Yolo V8x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GI2eSHtWPo5v","outputId":"a3553676-a969-4282-9900-037badd89b82","trusted":true},"outputs":[],"source":[" # Loading a pretrained model\n","model = YOLO('yolov8x.pt')\n","\n","# Training the model\n","model.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n","            epochs = 100,\n","            imgsz = height,\n","            seed = 42,\n","            batch = 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVKMxLKMQhSr","trusted":true},"outputs":[],"source":["%matplotlib inline\n","# read in the results.csv file as a pandas dataframe\n","df = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\n","df.columns = df.columns.str.strip()\n","\n","# create subplots using seaborn\n","fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n","\n","# plot the columns using seaborn\n","sns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\n","sns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\n","sns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\n","sns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\n","sns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\n","sns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\n","sns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\n","sns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\n","sns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\n","sns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n","\n","# set titles and axis labels for each subplot\n","axs[0,0].set(title='Train Box Loss')\n","axs[0,1].set(title='Train Class Loss')\n","axs[1,0].set(title='Train DFL Loss')\n","axs[1,1].set(title='Metrics Precision (B)')\n","axs[2,0].set(title='Metrics Recall (B)')\n","axs[2,1].set(title='Metrics mAP50 (B)')\n","axs[3,0].set(title='Metrics mAP50-95 (B)')\n","axs[3,1].set(title='Validation Box Loss')\n","axs[4,0].set(title='Validation Class Loss')\n","axs[4,1].set(title='Validation DFL Loss')\n","\n","# add suptitle and subheader\n","plt.suptitle('Training Metrics and Loss', fontsize=24)\n","\n","# adjust top margin to make space for suptitle\n","plt.subplots_adjust(top=0.8)\n","\n","# adjust spacing between subplots\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTBE19nlGGHn","trusted":true},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.image as mpimg\n","# Reading the confusion matrix image file\n","img = mpimg.imread('/kaggle/working/runs/detect/train/confusion_matrix.png')\n","\n","# Plotting the confusion matrix image\n","fig, ax = plt.subplots(figsize = (15, 15))\n","\n","ax.imshow(img)\n","ax.axis('off');"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Yolo V8n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Loading a pretrained model\n","model = YOLO('yolov8n.pt')\n","\n","# Training the model\n","model.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n","            epochs = 100,\n","            imgsz = height,\n","            seed = 42,\n","            batch = 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%matplotlib inline\n","# read in the results.csv file as a pandas dataframe\n","df = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\n","df.columns = df.columns.str.strip()\n","\n","# create subplots using seaborn\n","fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n","\n","# plot the columns using seaborn\n","sns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\n","sns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\n","sns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\n","sns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\n","sns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\n","sns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\n","sns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\n","sns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\n","sns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\n","sns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n","\n","# set titles and axis labels for each subplot\n","axs[0,0].set(title='Train Box Loss')\n","axs[0,1].set(title='Train Class Loss')\n","axs[1,0].set(title='Train DFL Loss')\n","axs[1,1].set(title='Metrics Precision (B)')\n","axs[2,0].set(title='Metrics Recall (B)')\n","axs[2,1].set(title='Metrics mAP50 (B)')\n","axs[3,0].set(title='Metrics mAP50-95 (B)')\n","axs[3,1].set(title='Validation Box Loss')\n","axs[4,0].set(title='Validation Class Loss')\n","axs[4,1].set(title='Validation DFL Loss')\n","\n","# add suptitle and subheader\n","plt.suptitle('Training Metrics and Loss', fontsize=24)\n","\n","# adjust top margin to make space for suptitle\n","plt.subplots_adjust(top=0.8)\n","\n","# adjust spacing between subplots\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.image as mpimg\n","# Reading the confusion matrix image file\n","img = mpimg.imread('/kaggle/working/runs/detect/train/confusion_matrix.png')\n","\n","# Plotting the confusion matrix image\n","fig, ax = plt.subplots(figsize = (15, 15))\n","\n","ax.imshow(img)\n","ax.axis('off');"]},{"cell_type":"markdown","metadata":{},"source":["# Yolo V9"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Loading a pretrained model\n","model = YOLO('yolov9c.pt')\n","\n","# Training the model\n","model.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n","            epochs = 200,\n","            imgsz = height,\n","            seed = 42,\n","            batch = 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%matplotlib inline\n","# read in the results.csv file as a pandas dataframe\n","df = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\n","df.columns = df.columns.str.strip()\n","     \n","# create subplots using seaborn \n","fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n","\n","# plot the columns using seaborn\n","sns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\n","sns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\n","sns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\n","sns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\n","sns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\n","sns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\n","sns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\n","sns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\n","sns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\n","sns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n","\n","# set titles and axis labels for each subplot\n","axs[0,0].set(title='Train Box Loss')\n","axs[0,1].set(title='Train Class Loss')\n","axs[1,0].set(title='Train DFL Loss')\n","axs[1,1].set(title='Metrics Precision (B)')\n","axs[2,0].set(title='Metrics Recall (B)')\n","axs[2,1].set(title='Metrics mAP50 (B)')\n","axs[3,0].set(title='Metrics mAP50-95 (B)')\n","axs[3,1].set(title='Validation Box Loss')\n","axs[4,0].set(title='Validation Class Loss')\n","axs[4,1].set(title='Validation DFL Loss')\n","\n","# add suptitle and subheader\n","plt.suptitle('Training Metrics and Loss', fontsize=24)\n","\n","# adjust top margin to make space for suptitle\n","plt.subplots_adjust(top=0.8)\n","\n","# adjust spacing between subplots\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.image as mpimg\n","# Reading the confusion matrix image file\n","img = mpimg.imread('/kaggle/working/runs/detect/train/confusion_matrix.png')\n","\n","# Plotting the confusion matrix image\n","fig, ax = plt.subplots(figsize = (15, 15))\n","\n","ax.imshow(img)\n","ax.axis('off');"]},{"cell_type":"markdown","metadata":{"id":"Km04xeXXHI5c"},"source":["# Prediction on Test Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1VHaYrDFwIa"},"outputs":[],"source":["# prompt: make a code that it save this path /content/runs/detect/train/weights/best.pt file to our google drive folder path /content/drive/MyDrive/Datasets/Ships_Dataset_25_classes\n","# copies the target file to the destination folder\n","# !cp /content/runs/detect/train/weights/best.pt /content/drive/MyDrive/Datasets/Ships_Dataset_25_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lf9aLqDhHPvV","trusted":true},"outputs":[],"source":["# Loading the best model\n","model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n","\n","# Function to perform ship detections\n","def ship_detect(img_path):\n","\n","    # Read the image\n","    img = cv2.imread(img_path)\n","\n","    # Pass the image through the detection model and get the result\n","    detect_result = model(img)\n","\n","    # Plot the detections\n","    detect_img = detect_result[0].plot()\n","\n","    # Convert the image to RGB format\n","    detect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)\n","\n","    return detect_img"]},{"cell_type":"markdown","metadata":{"id":"GM5mSKxtu1-F"},"source":["Prediction on 36 Images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZpNv_oZDG3GY","outputId":"d64a16fe-f440-440a-a3b9-2328ae05184e","trusted":true},"outputs":[],"source":["import random\n","import os\n","# Define the directory where the custom images are stored\n","custom_image_dir = '/kaggle/input/ships-data-yolo-version-25classes/valid/images'\n","\n","# Get the list of image files in the directory\n","image_files = os.listdir(custom_image_dir)\n","\n","# Select 16 random images from the list\n","selected_images = random.sample(image_files, 36)\n","\n","# Create a figure with subplots for each image\n","fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(25, 25))\n","\n","# Iterate over the selected images and plot each one\n","for i, img_file in enumerate(selected_images):\n","\n","    # Compute the row and column index of the current subplot\n","    row_idx = i // 6\n","    col_idx = i % 6\n","\n","    # Load the current image and run object detection\n","    img_path = os.path.join(custom_image_dir, img_file)\n","    detect_img = ship_detect(img_path)\n","\n","    # Plot the current image on the appropriate subplot\n","    axes[row_idx, col_idx].imshow(detect_img)\n","    axes[row_idx, col_idx].axis('off')\n","\n","# Adjust the spacing between the subplots\n","plt.subplots_adjust(wspace=0.05, hspace=0.05)"]},{"cell_type":"markdown","metadata":{"id":"ku2ozLmau6zf"},"source":["Prediction on 16 Images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"J-PtVza3HasB","outputId":"1b04dc71-fc52-4dcb-89a5-69e3dd4bec87","trusted":true},"outputs":[],"source":["import random\n","import os\n","import cv2\n","\n","# Define the directory where the custom images are stored\n","custom_image_dir = '/kaggle/input/ships-data-yolo-version-25classes/valid/images'\n","\n","# Get the list of image files in the directory\n","image_files = os.listdir(custom_image_dir)\n","\n","# Select 16 random images from the list\n","selected_images = random.sample(image_files, 16)\n","\n","# Create a figure with subplots for each image\n","fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(25, 25))\n","\n","# Iterate over the selected images and plot each one\n","for i, img_file in enumerate(selected_images):\n","\n","    # Compute the row and column index of the current subplot\n","    row_idx = i // 4\n","    col_idx = i % 4\n","\n","    # Load the current image and run object detection\n","    img_path = os.path.join(custom_image_dir, img_file)\n","    detect_img = ship_detect(img_path)\n","\n","    # Plot the current image on the appropriate subplot\n","    axes[row_idx, col_idx].imshow(detect_img)\n","    axes[row_idx, col_idx].axis('off')\n","\n","# Adjust the spacing between the subplots\n","plt.subplots_adjust(wspace=0.05, hspace=0.05)"]},{"cell_type":"markdown","metadata":{"id":"NIX2TGZYu-jc"},"source":["Prediction on 1 Custom Image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"d8GxpVSWI0w4","outputId":"146f7e65-bc51-4fa4-cb76-8be1c53debc9"},"outputs":[],"source":["import cv2\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","import torch\n","\n","# Load the custom image\n","model = YOLO('/content/drive/MyDrive/Datasets/Ships_Dataset_25_classes/best_model/best_model.pt')\n","custom_image_path = \"/content/navy_ships.jpg\"\n","# Load the image using OpenCV\n","img = cv2.imread(custom_image_path)\n","\n","# Convert the image to RGB (OpenCV loads images in BGR format)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","# Convert the image to a PIL image\n","img_pil = Image.fromarray(img)\n","\n","# Transform the image to 640x640 and convert to tensor\n","transform = transforms.Compose([\n","    transforms.Resize((640, 640)),\n","    transforms.ToTensor(),\n","])\n","img_tensor = transform(img_pil)\n","\n","# Add a batch dimension (required by the model)\n","img_tensor = img_tensor.unsqueeze(0)\n","\n","# Pass the image through the detection model and get the result\n","detect_result = model(img_tensor)\n","detect_img = detect_result[0].plot()  # Modify this line as needed for your model's output\n","\n","# Convert the image to RGB format (if detect_img is in BGR)\n","detect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)\n","\n","# Show the image with the object detections\n","plt.imshow(detect_img)\n","plt.axis('off')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"1dx3dPqbiaV0"},"source":["# Implementing SAHI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wa_zsVYvicxA","outputId":"19d0e9b9-f418-422c-ecab-b389da0a15e4","trusted":true},"outputs":[],"source":["!pip install -U torch sahi yolov8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9He7PErwhTPH"},"outputs":[],"source":["from sahi import AutoDetectionModel\n","from sahi.predict import get_prediction, get_sliced_prediction, predict\n","from sahi.utils.cv import read_image\n","from sahi.utils.file import download_from_url\n","from sahi.utils.yolov8 import download_yolov8s_model ,  download_yolov8x_model\n","\n","# arrange instance segment model for test\n","from sahi.utils.yolov8 import (\n","    download_yolov8x_model\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9SfsDcYjWsp"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/Datasets/Ships_Dataset_25_classes/best_model/best_model.pt'\n","\n","download_yolov8x_model(destination_path= model_path)"]},{"cell_type":"markdown","metadata":{"id":"u1gjdNqNj5qp"},"source":["# Standard Inference full image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MDGJKtcjmYy"},"outputs":[],"source":["# standard Inference Model instructions\n","detection_model = AutoDetectionModel.from_pretrained(\n","    model_type = 'yolov8',\n","    model_path = model_path,\n","    confidence_threshold = 0.10,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDWCmSfUkcY2","outputId":"d9dbb99b-5a71-4410-dfa2-08e55e2d0d57"},"outputs":[],"source":["# Preform Predictions\n","result = get_prediction('/content/navy_ships.jpg', detection_model)\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9k6Rnkuk-jw","outputId":"cd019007-6bfd-4d25-bfb0-432b13fd5d59"},"outputs":[],"source":["# get the annotations results\n","result_data = result.to_coco_annotations()\n","result_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdKydvDUt4Fh","outputId":"949792e3-9506-49ef-de1b-6fe936f4c897"},"outputs":[],"source":["# getting information\n","for index in range(len(result_data)):\n","    print(f\"Category : {result_data[index]['category_name']} and Confidence Score : {result_data[index]['score']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56I3E-b8lF_L"},"outputs":[],"source":["result.export_visuals(export_dir = \"/content/\",  text_size= 0.35)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"YQcLSs-rmhcs","outputId":"1b7c3479-e022-4370-8024-9523d7683c3e"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Read the image\n","img = mpimg.imread('/content/prediction_visual.png')\n","\n","# Plot the image\n","plt.imshow(img)\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"nwS3zdL0gMDq"},"source":["# Sliced Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTcUMlWJfwXJ","outputId":"c4995d7a-7f9a-4e10-8add-5eec6f0de389"},"outputs":[],"source":["result = get_sliced_prediction(\n","    '/content/navy_ships.jpg',\n","    detection_model ,\n","    slice_height= 100,  # chage the slice size ccording to image\n","    slice_width = 100,  # chage the slice size ccording to image\n","    overlap_height_ratio = 0.3,\n","    overlap_width_ratio = 0.3,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmNystrrg9XO","outputId":"1d0b3018-264e-4b4f-efdc-29f9442ae355"},"outputs":[],"source":["result_data = result.to_coco_annotations()\n","result_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBsqAR4ytot5","outputId":"e4e094ab-3eb8-41b9-e665-2a4f0e48b8c9"},"outputs":[],"source":["# getting information\n","for index in range(len(result_data)):\n","    print(f\"Category : {result_data[index]['category_name']} and Confidence Score : {result_data[index]['score']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CAdds5agkLv"},"outputs":[],"source":["result.export_visuals(export_dir = \"/content/\", text_size= 0.35)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"H8fuQJmlgzyU","outputId":"a20d7756-114b-4f59-b0d7-20f46e2a602f"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Read the image\n","img = mpimg.imread('/content/prediction_visual.png')\n","\n","# Plot the image\n","plt.imshow(img)\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LT5I_7XVrCTs"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5088591,"sourceId":8522130,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
