{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8522130,"sourceType":"datasetVersion","datasetId":5088591}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* Dataset = https://universe.roboflow.com/backdoor-experiment/corruptedlabel-backdoor-ac10per   25 classes\n\n* ref_notebook = https://www.kaggle.com/code/billiemage/object-detection\n\n\n1.  Airraft carrier\n2.  Auxiliary Ships\n3.  Barge\n4.  Cargo\n5.  Commander\n6.  Container Ship\n7.  Cruiser\n8.  Destroyer\n9.  Dock\n10. Ferry\n11. Fishing Vessel\n12. Frigate\n13. Hovercraft\n14. Landing Ship\n15. Motorboat\n16. Oil tanker\n17. Merchant Ship\n18. Other Ship\n19. Other Warship\n20. Patrol\n21. RORO\n22. Sailboat\n23. Submarine\n24. Tugboat\n25. Yacht","metadata":{"id":"Zvsk7icHMTni"}},{"cell_type":"code","source":"# Import basic Libaries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn\n%matplotlib inline\nplt.style.use('default')","metadata":{"id":"2BDMpzqTMPV0","execution":{"iopub.status.busy":"2024-06-13T09:02:28.572230Z","iopub.execute_input":"2024-06-13T09:02:28.572590Z","iopub.status.idle":"2024-06-13T09:02:29.604628Z","shell.execute_reply.started":"2024-06-13T09:02:28.572560Z","shell.execute_reply":"2024-06-13T09:02:29.603867Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn # nn imports all pytorch building blocks for neural networking\ntorch.__version__\n\n# Make device agnostic code\nimport torch._dynamo.config\ntorch._dynamo.config.suppress_errors = True # pytorch 2.0 to use torch.compile\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"pT5fWn2bMYIr","outputId":"09d072ed-9391-4036-acdb-0fa62e392dc4","execution":{"iopub.status.busy":"2024-06-13T09:02:30.704611Z","iopub.execute_input":"2024-06-13T09:02:30.705131Z","iopub.status.idle":"2024-06-13T09:02:37.313179Z","shell.execute_reply.started":"2024-06-13T09:02:30.705080Z","shell.execute_reply":"2024-06-13T09:02:37.312158Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# Import Torch Vision\nimport torchvision\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor  # transforms images to tensors","metadata":{"id":"9YEBBeuAMZhN","execution":{"iopub.status.busy":"2024-06-13T09:02:37.314704Z","iopub.execute_input":"2024-06-13T09:02:37.315174Z","iopub.status.idle":"2024-06-13T09:02:37.638309Z","shell.execute_reply.started":"2024-06-13T09:02:37.315146Z","shell.execute_reply":"2024-06-13T09:02:37.637573Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# to take model information\ntry:\n    import torchinfo\nexcept:\n    !pip install torchinfo\n    import torchinfo\n\nfrom torchinfo import summary","metadata":{"id":"NFBNPjyCMa7N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a50427b3-d3d8-4208-e827-9bdcaee1f4a0","execution":{"iopub.status.busy":"2024-06-13T09:02:37.639304Z","iopub.execute_input":"2024-06-13T09:02:37.639572Z","iopub.status.idle":"2024-06-13T09:02:37.653455Z","shell.execute_reply.started":"2024-06-13T09:02:37.639549Z","shell.execute_reply":"2024-06-13T09:02:37.652780Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKIEmXcSMdsq","outputId":"d43a38d2-a841-4744-d39f-c3ba210c22ba","execution":{"iopub.status.busy":"2024-06-13T09:02:37.655666Z","iopub.execute_input":"2024-06-13T09:02:37.656074Z","iopub.status.idle":"2024-06-13T09:02:53.069852Z","shell.execute_reply.started":"2024-06-13T09:02:37.656043Z","shell.execute_reply":"2024-06-13T09:02:53.068693Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.31-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m723.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.4)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=0.2.5 (from ultralytics)\n  Downloading ultralytics_thop-0.2.8-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.31-py3-none-any.whl (780 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m780.6/780.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-0.2.8-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.31 ultralytics-thop-0.2.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"Nl8unNxqMln2"}},{"cell_type":"code","source":"train_images = \"/kaggle/input/ships-data-yolo-version-25classes/train/images\"\ntrain_labels = \"/kaggle/input/ships-data-yolo-version-25classes/train/labels\"\n\nval_images = \"/kaggle/input/ships-data-yolo-version-25classes/valid/images\"\nval_labels = \"/kaggle/input/ships-data-yolo-version-25classes/valid/labels\"\n\ndata_yaml = \"/kaggle/input/ships-data-yolo-version-25classes/data.yaml\"","metadata":{"id":"xRpgGgyhOWTu","execution":{"iopub.status.busy":"2024-06-13T09:02:53.071216Z","iopub.execute_input":"2024-06-13T09:02:53.071510Z","iopub.status.idle":"2024-06-13T09:02:53.080924Z","shell.execute_reply.started":"2024-06-13T09:02:53.071482Z","shell.execute_reply":"2024-06-13T09:02:53.080190Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"UZYj3j--QSED"}},{"cell_type":"code","source":"# Load an image using OpenCV\nimport cv2\nimage = cv2.imread(\"/kaggle/input/ships-data-yolo-version-25classes/train/images/000006_bmp_jpg.rf.fe44953b88a4d81b3fdd6309597fad07.jpg\")\n\n# Get the size of the image\nheight, width, channels = image.shape\nprint(f\"The image has dimensions {width}x{height} and {channels} channels.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U31X46qdQzIm","outputId":"fcc35453-4db4-493d-9e08-e2706eabab65","execution":{"iopub.status.busy":"2024-06-13T09:02:53.081951Z","iopub.execute_input":"2024-06-13T09:02:53.082246Z","iopub.status.idle":"2024-06-13T09:02:53.376040Z","shell.execute_reply.started":"2024-06-13T09:02:53.082213Z","shell.execute_reply":"2024-06-13T09:02:53.375150Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"The image has dimensions 640x640 and 3 channels.\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"id":"Z78ayOqCvPC6","execution":{"iopub.status.busy":"2024-06-13T09:02:53.377241Z","iopub.execute_input":"2024-06-13T09:02:53.377534Z","iopub.status.idle":"2024-06-13T09:02:53.506536Z","shell.execute_reply.started":"2024-06-13T09:02:53.377507Z","shell.execute_reply":"2024-06-13T09:02:53.505465Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# YOLOv9-x","metadata":{}},{"cell_type":"code","source":" # Loading a pretrained model\nmodel = YOLO('yolov9e.pt')\n\n# Training the model\nmodel.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n            epochs = 100,\n            imgsz = height,\n            seed = 42,\n            batch = 8)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:02:53.507618Z","iopub.execute_input":"2024-06-13T09:02:53.507936Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9e.pt to 'yolov9e.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112M/112M [00:00<00:00, 250MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.2.31 üöÄ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9e.pt, data=/kaggle/input/ships-data-yolo-version-25classes/data.yaml, epochs=100, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 14.4MB/s]\n2024-06-13 09:02:57,577\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-13 09:02:58,439\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=25\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1         0  ultralytics.nn.modules.block.Silence         []                            \n  1                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  2                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  3                  -1  1    252160  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 2]        \n  4                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n  5                  -1  1   1004032  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 2]       \n  6                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n  7                  -1  1   4006912  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 1024, 512, 256, 2]      \n  8                  -1  1   2623488  ultralytics.nn.modules.block.ADown           [1024, 1024]                  \n  9                  -1  1   4269056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 1024, 512, 256, 2]     \n 10                   1  1      4160  ultralytics.nn.modules.block.CBLinear        [64, [64]]                    \n 11                   3  1     49344  ultralytics.nn.modules.block.CBLinear        [256, [64, 128]]              \n 12                   5  1    229824  ultralytics.nn.modules.block.CBLinear        [512, [64, 128, 256]]         \n 13                   7  1    984000  ultralytics.nn.modules.block.CBLinear        [1024, [64, 128, 256, 512]]   \n 14                   9  1   2033600  ultralytics.nn.modules.block.CBLinear        [1024, [64, 128, 256, 512, 1024]]\n 15                   0  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n 16[10, 11, 12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[0, 0, 0, 0, 0]]             \n 17                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n 18[11, 12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[1, 1, 1, 1]]                \n 19                  -1  1    252160  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 2]        \n 20                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n 21    [12, 13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[2, 2, 2]]                   \n 22                  -1  1   1004032  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 2]       \n 23                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n 24        [13, 14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[3, 3]]                      \n 25                  -1  1   4006912  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 1024, 512, 256, 2]      \n 26                  -1  1   2623488  ultralytics.nn.modules.block.ADown           [1024, 1024]                  \n 27            [14, -1]  1         0  ultralytics.nn.modules.block.CBFuse          [[4]]                         \n 28                  -1  1   4269056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 1024, 512, 256, 2]     \n 29                  -1  1    787968  ultralytics.nn.modules.block.SPPELAN         [1024, 512, 256]              \n 30                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 31            [-1, 25]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 32                  -1  1   4005888  ultralytics.nn.modules.block.RepNCSPELAN4    [1536, 512, 512, 256, 2]      \n 33                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 34            [-1, 22]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 35                  -1  1   1069056  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 2]      \n 36                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n 37            [-1, 32]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 38                  -1  1   3612672  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 2]       \n 39                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n 40            [-1, 29]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 41                  -1  1  12860416  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 1024, 512, 2]     \n 42        [35, 38, 41]  1   5602075  ultralytics.nn.modules.head.Detect           [25, [256, 512, 512]]         \nYOLOv9e summary: 1225 layers, 58164187 parameters, 58164171 gradients, 192.8 GFLOPs\n\nTransferred 1805/1811 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240613_090340-r49sioma</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tejasdashpute/YOLOv8/runs/r49sioma' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/tejasdashpute/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tejasdashpute/YOLOv8' target=\"_blank\">https://wandb.ai/tejasdashpute/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tejasdashpute/YOLOv8/runs/r49sioma' target=\"_blank\">https://wandb.ai/tejasdashpute/YOLOv8/runs/r49sioma</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.42.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 71.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/ships-data-yolo-version-25classes/train/labels... 2209 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2209/2209 [00:08<00:00, 256.56it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/train/images/003313_bmp_jpg.rf.d20a8e352ccf1762ddbe11b05e6f329f.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/train/images/004153_bmp_jpg.rf.10f2ada766e80f906426e4dabb127ddb.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/train/images/2487__0_1498_bmp_jpg.rf.20b79625c01640e63a45c6e6b4a11a3c.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/train/images/2562__2760_2345_bmp_jpg.rf.b1acc85b79c4e43c2e23a5250cea08b8.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/train/images/2562__3207_2345_bmp_jpg.rf.e2520ff5600701c11e410d3667e98ece.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/train/images/2564__1840_2345_bmp_jpg.rf.41977998c1ff6553085935406caa017f.jpg: 2 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/ships-data-yolo-version-25classes/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/ships-data-yolo-version-25classes/valid/labels... 553 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 553/553 [00:02<00:00, 252.54it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/valid/images/1418__0_0_bmp_jpg.rf.d3388579efa061739f5f27cc588d441c.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/valid/images/1907__2012_1840_bmp_jpg.rf.5ce541da79da79a419318b032daac34a.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/ships-data-yolo-version-25classes/valid/images/2562__3207_1840_bmp_jpg.rf.27bc9d2d39389f490c71884e8d321c89.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/ships-data-yolo-version-25classes/valid is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000345, momentum=0.9) with parameter groups 298 weight(decay=0.0), 310 weight(decay=0.0005), 309 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      12.4G      1.131      2.879      1.258         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [03:58<00:00,  1.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:23<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        553       3035      0.258      0.251      0.123     0.0799\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100        12G      1.102      2.263      1.244         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [03:48<00:00,  1.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:22<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        553       3035      0.183      0.321      0.197      0.134\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      11.6G      1.108      2.153      1.271         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [03:45<00:00,  1.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:22<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        553       3035      0.238      0.374      0.243      0.166\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      11.6G      1.116      2.093       1.26          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [03:45<00:00,  1.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:22<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        553       3035      0.482      0.304      0.257      0.178\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      11.4G      1.082      1.977      1.238         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [03:45<00:00,  1.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:21<00:00,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        553       3035      0.428      0.363      0.326       0.23\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      12.2G      1.021      1.782      1.205          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 277/277 [03:45<00:00,  1.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:21<00:00,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        553       3035      0.405       0.43      0.362      0.263\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      11.4G     0.9932      1.731      1.188         56        640:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 240/277 [03:15<00:29,  1.24it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"# Yolo V8x","metadata":{}},{"cell_type":"code","source":" # Loading a pretrained model\nmodel = YOLO('yolov8x.pt')\n\n# Training the model\nmodel.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n            epochs = 100,\n            imgsz = height,\n            seed = 42,\n            batch = 8)","metadata":{"id":"GI2eSHtWPo5v","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a3553676-a969-4282-9900-037badd89b82","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n# read in the results.csv file as a pandas dataframe\ndf = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\ndf.columns = df.columns.str.strip()\n\n# create subplots using seaborn\nfig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n\n# plot the columns using seaborn\nsns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\nsns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\nsns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\nsns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\nsns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\nsns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\nsns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\nsns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\nsns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\nsns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n\n# set titles and axis labels for each subplot\naxs[0,0].set(title='Train Box Loss')\naxs[0,1].set(title='Train Class Loss')\naxs[1,0].set(title='Train DFL Loss')\naxs[1,1].set(title='Metrics Precision (B)')\naxs[2,0].set(title='Metrics Recall (B)')\naxs[2,1].set(title='Metrics mAP50 (B)')\naxs[3,0].set(title='Metrics mAP50-95 (B)')\naxs[3,1].set(title='Validation Box Loss')\naxs[4,0].set(title='Validation Class Loss')\naxs[4,1].set(title='Validation DFL Loss')\n\n# add suptitle and subheader\nplt.suptitle('Training Metrics and Loss', fontsize=24)\n\n# adjust top margin to make space for suptitle\nplt.subplots_adjust(top=0.8)\n\n# adjust spacing between subplots\nplt.tight_layout()\n\nplt.show()","metadata":{"id":"oVKMxLKMQhSr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.image as mpimg\n# Reading the confusion matrix image file\nimg = mpimg.imread('/kaggle/working/runs/detect/train/confusion_matrix.png')\n\n# Plotting the confusion matrix image\nfig, ax = plt.subplots(figsize = (15, 15))\n\nax.imshow(img)\nax.axis('off');","metadata":{"id":"NTBE19nlGGHn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Yolo V8n","metadata":{}},{"cell_type":"code","source":"# Loading a pretrained model\nmodel = YOLO('yolov8n.pt')\n\n# Training the model\nmodel.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n            epochs = 100,\n            imgsz = height,\n            seed = 42,\n            batch = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n# read in the results.csv file as a pandas dataframe\ndf = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\ndf.columns = df.columns.str.strip()\n\n# create subplots using seaborn\nfig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n\n# plot the columns using seaborn\nsns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\nsns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\nsns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\nsns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\nsns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\nsns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\nsns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\nsns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\nsns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\nsns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n\n# set titles and axis labels for each subplot\naxs[0,0].set(title='Train Box Loss')\naxs[0,1].set(title='Train Class Loss')\naxs[1,0].set(title='Train DFL Loss')\naxs[1,1].set(title='Metrics Precision (B)')\naxs[2,0].set(title='Metrics Recall (B)')\naxs[2,1].set(title='Metrics mAP50 (B)')\naxs[3,0].set(title='Metrics mAP50-95 (B)')\naxs[3,1].set(title='Validation Box Loss')\naxs[4,0].set(title='Validation Class Loss')\naxs[4,1].set(title='Validation DFL Loss')\n\n# add suptitle and subheader\nplt.suptitle('Training Metrics and Loss', fontsize=24)\n\n# adjust top margin to make space for suptitle\nplt.subplots_adjust(top=0.8)\n\n# adjust spacing between subplots\nplt.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.image as mpimg\n# Reading the confusion matrix image file\nimg = mpimg.imread('/kaggle/working/runs/detect/train/confusion_matrix.png')\n\n# Plotting the confusion matrix image\nfig, ax = plt.subplots(figsize = (15, 15))\n\nax.imshow(img)\nax.axis('off');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Yolo V9","metadata":{}},{"cell_type":"code","source":"# Loading a pretrained model\nmodel = YOLO('yolov9c.pt')\n\n# Training the model\nmodel.train(data = '/kaggle/input/ships-data-yolo-version-25classes/data.yaml',\n            epochs = 200,\n            imgsz = height,\n            seed = 42,\n            batch = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n# read in the results.csv file as a pandas dataframe\ndf = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\ndf.columns = df.columns.str.strip()\n     \n# create subplots using seaborn \nfig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n\n# plot the columns using seaborn\nsns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\nsns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\nsns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\nsns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\nsns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\nsns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\nsns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\nsns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\nsns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\nsns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n\n# set titles and axis labels for each subplot\naxs[0,0].set(title='Train Box Loss')\naxs[0,1].set(title='Train Class Loss')\naxs[1,0].set(title='Train DFL Loss')\naxs[1,1].set(title='Metrics Precision (B)')\naxs[2,0].set(title='Metrics Recall (B)')\naxs[2,1].set(title='Metrics mAP50 (B)')\naxs[3,0].set(title='Metrics mAP50-95 (B)')\naxs[3,1].set(title='Validation Box Loss')\naxs[4,0].set(title='Validation Class Loss')\naxs[4,1].set(title='Validation DFL Loss')\n\n# add suptitle and subheader\nplt.suptitle('Training Metrics and Loss', fontsize=24)\n\n# adjust top margin to make space for suptitle\nplt.subplots_adjust(top=0.8)\n\n# adjust spacing between subplots\nplt.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.image as mpimg\n# Reading the confusion matrix image file\nimg = mpimg.imread('/kaggle/working/runs/detect/train/confusion_matrix.png')\n\n# Plotting the confusion matrix image\nfig, ax = plt.subplots(figsize = (15, 15))\n\nax.imshow(img)\nax.axis('off');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction on Test Images","metadata":{"id":"Km04xeXXHI5c"}},{"cell_type":"code","source":"# prompt: make a code that it save this path /content/runs/detect/train/weights/best.pt file to our google drive folder path /content/drive/MyDrive/Datasets/Ships_Dataset_25_classes\n# copies the target file to the destination folder\n# !cp /content/runs/detect/train/weights/best.pt /content/drive/MyDrive/Datasets/Ships_Dataset_25_classes","metadata":{"id":"K1VHaYrDFwIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the best model\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# Function to perform ship detections\ndef ship_detect(img_path):\n\n    # Read the image\n    img = cv2.imread(img_path)\n\n    # Pass the image through the detection model and get the result\n    detect_result = model(img)\n\n    # Plot the detections\n    detect_img = detect_result[0].plot()\n\n    # Convert the image to RGB format\n    detect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)\n\n    return detect_img","metadata":{"id":"lf9aLqDhHPvV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction on 36 Images\n","metadata":{"id":"GM5mSKxtu1-F"}},{"cell_type":"code","source":"import random\nimport os\n# Define the directory where the custom images are stored\ncustom_image_dir = '/kaggle/input/ships-data-yolo-version-25classes/valid/images'\n\n# Get the list of image files in the directory\nimage_files = os.listdir(custom_image_dir)\n\n# Select 16 random images from the list\nselected_images = random.sample(image_files, 36)\n\n# Create a figure with subplots for each image\nfig, axes = plt.subplots(nrows=6, ncols=6, figsize=(25, 25))\n\n# Iterate over the selected images and plot each one\nfor i, img_file in enumerate(selected_images):\n\n    # Compute the row and column index of the current subplot\n    row_idx = i // 6\n    col_idx = i % 6\n\n    # Load the current image and run object detection\n    img_path = os.path.join(custom_image_dir, img_file)\n    detect_img = ship_detect(img_path)\n\n    # Plot the current image on the appropriate subplot\n    axes[row_idx, col_idx].imshow(detect_img)\n    axes[row_idx, col_idx].axis('off')\n\n# Adjust the spacing between the subplots\nplt.subplots_adjust(wspace=0.05, hspace=0.05)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZpNv_oZDG3GY","outputId":"d64a16fe-f440-440a-a3b9-2328ae05184e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction on 16 Images\n","metadata":{"id":"ku2ozLmau6zf"}},{"cell_type":"code","source":"import random\nimport os\nimport cv2\n\n# Define the directory where the custom images are stored\ncustom_image_dir = '/kaggle/input/ships-data-yolo-version-25classes/valid/images'\n\n# Get the list of image files in the directory\nimage_files = os.listdir(custom_image_dir)\n\n# Select 16 random images from the list\nselected_images = random.sample(image_files, 16)\n\n# Create a figure with subplots for each image\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(25, 25))\n\n# Iterate over the selected images and plot each one\nfor i, img_file in enumerate(selected_images):\n\n    # Compute the row and column index of the current subplot\n    row_idx = i // 4\n    col_idx = i % 4\n\n    # Load the current image and run object detection\n    img_path = os.path.join(custom_image_dir, img_file)\n    detect_img = ship_detect(img_path)\n\n    # Plot the current image on the appropriate subplot\n    axes[row_idx, col_idx].imshow(detect_img)\n    axes[row_idx, col_idx].axis('off')\n\n# Adjust the spacing between the subplots\nplt.subplots_adjust(wspace=0.05, hspace=0.05)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"J-PtVza3HasB","outputId":"1b04dc71-fc52-4dcb-89a5-69e3dd4bec87","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction on 1 Custom Image\n","metadata":{"id":"NIX2TGZYu-jc"}},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch\n\n# Load the custom image\nmodel = YOLO('/content/drive/MyDrive/Datasets/Ships_Dataset_25_classes/best_model/best_model.pt')\ncustom_image_path = \"/content/navy_ships.jpg\"\n# Load the image using OpenCV\nimg = cv2.imread(custom_image_path)\n\n# Convert the image to RGB (OpenCV loads images in BGR format)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n# Convert the image to a PIL image\nimg_pil = Image.fromarray(img)\n\n# Transform the image to 640x640 and convert to tensor\ntransform = transforms.Compose([\n    transforms.Resize((640, 640)),\n    transforms.ToTensor(),\n])\nimg_tensor = transform(img_pil)\n\n# Add a batch dimension (required by the model)\nimg_tensor = img_tensor.unsqueeze(0)\n\n# Pass the image through the detection model and get the result\ndetect_result = model(img_tensor)\ndetect_img = detect_result[0].plot()  # Modify this line as needed for your model's output\n\n# Convert the image to RGB format (if detect_img is in BGR)\ndetect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)\n\n# Show the image with the object detections\nplt.imshow(detect_img)\nplt.axis('off')\nplt.show()\n","metadata":{"id":"d8GxpVSWI0w4","colab":{"base_uri":"https://localhost:8080/","height":458},"outputId":"146f7e65-bc51-4fa4-cb76-8be1c53debc9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing SAHI","metadata":{"id":"1dx3dPqbiaV0"}},{"cell_type":"code","source":"!pip install -U torch sahi yolov8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wa_zsVYvicxA","outputId":"19d0e9b9-f418-422c-ecab-b389da0a15e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sahi import AutoDetectionModel\nfrom sahi.predict import get_prediction, get_sliced_prediction, predict\nfrom sahi.utils.cv import read_image\nfrom sahi.utils.file import download_from_url\nfrom sahi.utils.yolov8 import download_yolov8s_model ,  download_yolov8x_model\n\n# arrange instance segment model for test\nfrom sahi.utils.yolov8 import (\n    download_yolov8x_model\n)","metadata":{"id":"9He7PErwhTPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/content/drive/MyDrive/Datasets/Ships_Dataset_25_classes/best_model/best_model.pt'\n\ndownload_yolov8x_model(destination_path= model_path)","metadata":{"id":"H9SfsDcYjWsp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standard Inference full image","metadata":{"id":"u1gjdNqNj5qp"}},{"cell_type":"code","source":"# standard Inference Model instructions\ndetection_model = AutoDetectionModel.from_pretrained(\n    model_type = 'yolov8',\n    model_path = model_path,\n    confidence_threshold = 0.10,\n)","metadata":{"id":"4MDGJKtcjmYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preform Predictions\nresult = get_prediction('/content/navy_ships.jpg', detection_model)\nresult","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDWCmSfUkcY2","outputId":"d9dbb99b-5a71-4410-dfa2-08e55e2d0d57"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the annotations results\nresult_data = result.to_coco_annotations()\nresult_data","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9k6Rnkuk-jw","outputId":"cd019007-6bfd-4d25-bfb0-432b13fd5d59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting information\nfor index in range(len(result_data)):\n    print(f\"Category : {result_data[index]['category_name']} and Confidence Score : {result_data[index]['score']}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdKydvDUt4Fh","outputId":"949792e3-9506-49ef-de1b-6fe936f4c897"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.export_visuals(export_dir = \"/content/\",  text_size= 0.35)","metadata":{"id":"56I3E-b8lF_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Read the image\nimg = mpimg.imread('/content/prediction_visual.png')\n\n# Plot the image\nplt.imshow(img)\n\n# Show the plot\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"YQcLSs-rmhcs","outputId":"1b7c3479-e022-4370-8024-9523d7683c3e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sliced Predictions","metadata":{"id":"nwS3zdL0gMDq"}},{"cell_type":"code","source":"result = get_sliced_prediction(\n    '/content/navy_ships.jpg',\n    detection_model ,\n    slice_height= 100,  # chage the slice size ccording to image\n    slice_width = 100,  # chage the slice size ccording to image\n    overlap_height_ratio = 0.3,\n    overlap_width_ratio = 0.3,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTcUMlWJfwXJ","outputId":"c4995d7a-7f9a-4e10-8add-5eec6f0de389"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_data = result.to_coco_annotations()\nresult_data","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmNystrrg9XO","outputId":"1d0b3018-264e-4b4f-efdc-29f9442ae355"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting information\nfor index in range(len(result_data)):\n    print(f\"Category : {result_data[index]['category_name']} and Confidence Score : {result_data[index]['score']}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBsqAR4ytot5","outputId":"e4e094ab-3eb8-41b9-e665-2a4f0e48b8c9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.export_visuals(export_dir = \"/content/\", text_size= 0.35)","metadata":{"id":"9CAdds5agkLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Read the image\nimg = mpimg.imread('/content/prediction_visual.png')\n\n# Plot the image\nplt.imshow(img)\n\n# Show the plot\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"H8fuQJmlgzyU","outputId":"a20d7756-114b-4f59-b0d7-20f46e2a602f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"LT5I_7XVrCTs"},"execution_count":null,"outputs":[]}]}